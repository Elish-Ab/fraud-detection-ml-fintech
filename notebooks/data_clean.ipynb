{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../scripts') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-07 19:45:15,088 - INFO - Loading datasets...\n"
     ]
    }
   ],
   "source": [
    "# Load the datasets\n",
    "logging.info(\"Loading datasets...\")\n",
    "fraud_data = pd.read_csv('../data/Fraud_Data.csv')\n",
    "ip_to_country = pd.read_csv('../data/IpAddress_to_Country.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_cleaning import handle_missing_values,remove_duplicates_and_convert_types, univariate_analysis,bivariate_analysis, process_fraud_data,merge_geolocation, feature_engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-07 19:45:16,748 - INFO - Missing values before cleaning:\n",
      "2025-02-07 19:45:17,005 - INFO - user_id           0\n",
      "signup_time       0\n",
      "purchase_time     0\n",
      "purchase_value    0\n",
      "device_id         0\n",
      "source            0\n",
      "browser           0\n",
      "sex               0\n",
      "age               0\n",
      "ip_address        0\n",
      "class             0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id          signup_time        purchase_time  purchase_value  \\\n",
      "0    22058  2015-02-24 22:55:49  2015-04-18 02:47:11              34   \n",
      "1   333320  2015-06-07 20:39:50  2015-06-08 01:38:54              16   \n",
      "2     1359  2015-01-01 18:52:44  2015-01-01 18:52:45              15   \n",
      "3   150084  2015-04-28 21:13:25  2015-05-04 13:54:50              44   \n",
      "4   221365  2015-07-21 07:09:52  2015-09-09 18:40:53              39   \n",
      "\n",
      "       device_id source browser sex  age    ip_address  class  \n",
      "0  QVPSPJUOCKZAR    SEO  Chrome   M   39  7.327584e+08      0  \n",
      "1  EOGFQPIZPYXFZ    Ads  Chrome   F   53  3.503114e+08      0  \n",
      "2  YSSKYOSJHPPLJ    SEO   Opera   M   53  2.621474e+09      1  \n",
      "3  ATGTXKYKUDUQN    SEO  Safari   M   41  3.840542e+09      0  \n",
      "4  NAUITBZFJKHWW    Ads  Safari   M   45  4.155831e+08      0  \n"
     ]
    }
   ],
   "source": [
    "# Apply data cleaning functions step by step\n",
    "fraud_data = handle_missing_values(fraud_data)\n",
    "print(fraud_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-07 19:45:17,082 - INFO - Removing duplicates and converting time columns to datetime...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id         signup_time       purchase_time  purchase_value  \\\n",
      "0    22058 2015-02-24 22:55:49 2015-04-18 02:47:11              34   \n",
      "1   333320 2015-06-07 20:39:50 2015-06-08 01:38:54              16   \n",
      "2     1359 2015-01-01 18:52:44 2015-01-01 18:52:45              15   \n",
      "3   150084 2015-04-28 21:13:25 2015-05-04 13:54:50              44   \n",
      "4   221365 2015-07-21 07:09:52 2015-09-09 18:40:53              39   \n",
      "\n",
      "       device_id source browser sex  age    ip_address  class  \n",
      "0  QVPSPJUOCKZAR    SEO  Chrome   M   39  7.327584e+08      0  \n",
      "1  EOGFQPIZPYXFZ    Ads  Chrome   F   53  3.503114e+08      0  \n",
      "2  YSSKYOSJHPPLJ    SEO   Opera   M   53  2.621474e+09      1  \n",
      "3  ATGTXKYKUDUQN    SEO  Safari   M   41  3.840542e+09      0  \n",
      "4  NAUITBZFJKHWW    Ads  Safari   M   45  4.155831e+08      0  \n"
     ]
    }
   ],
   "source": [
    "fraud_data = remove_duplicates_and_convert_types(fraud_data)\n",
    "print(fraud_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-07 19:45:17,429 - INFO - Converting IP addresses to integers...\n",
      "2025-02-07 19:45:17,684 - INFO - Processed IP addresses. Sample data:\n",
      "0     732758368\n",
      "1     350311387\n",
      "2    2621473820\n",
      "3    3840542443\n",
      "4     415583117\n",
      "Name: ip_int, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Assuming fraud_data is already loaded as a pandas DataFrame\n",
    "fraud_data = process_fraud_data(fraud_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "user_id                    int64\n",
      "signup_time       datetime64[ns]\n",
      "purchase_time     datetime64[ns]\n",
      "purchase_value             int64\n",
      "device_id                 object\n",
      "source                    object\n",
      "browser                   object\n",
      "sex                       object\n",
      "age                        int64\n",
      "ip_address               float64\n",
      "class                      int64\n",
      "ip_int                     int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(type(fraud_data))  # Should be <class 'pandas.core.frame.DataFrame'>\n",
    "\n",
    "if isinstance(fraud_data, pd.DataFrame):\n",
    "    print(fraud_data.dtypes)  # Show column data types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(fraud_data))  # Expected output: <class 'pandas.core.frame.DataFrame'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-07 19:45:17,732 - INFO - Performing feature engineering...\n",
      "2025-02-07 19:45:17,885 - INFO - Normalizing continuous features...\n",
      "2025-02-07 19:45:17,900 - INFO - Performing one-hot encoding...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   user_id         signup_time       purchase_time  purchase_value  \\\n",
      "0    22058 2015-02-24 22:55:49 2015-04-18 02:47:11              34   \n",
      "1   333320 2015-06-07 20:39:50 2015-06-08 01:38:54              16   \n",
      "2     1359 2015-01-01 18:52:44 2015-01-01 18:52:45              15   \n",
      "3   150084 2015-04-28 21:13:25 2015-05-04 13:54:50              44   \n",
      "4   221365 2015-07-21 07:09:52 2015-09-09 18:40:53              39   \n",
      "\n",
      "       device_id  age    ip_address  class      ip_int  purchase_hour  ...  \\\n",
      "0  QVPSPJUOCKZAR   39  7.327584e+08      0   732758368              2  ...   \n",
      "1  EOGFQPIZPYXFZ   53  3.503114e+08      0   350311387              1  ...   \n",
      "2  YSSKYOSJHPPLJ   53  2.621474e+09      1  2621473820             18  ...   \n",
      "3  ATGTXKYKUDUQN   41  3.840542e+09      0  3840542443             13  ...   \n",
      "4  NAUITBZFJKHWW   45  4.155831e+08      0   415583117             18  ...   \n",
      "\n",
      "   purchase_value_scaled  age_scaled  transaction_count_scaled  source_Direct  \\\n",
      "0              -0.160204    0.679914                       0.0              0   \n",
      "1              -1.142592    2.304476                       0.0              0   \n",
      "2              -1.197169    2.304476                       0.0              0   \n",
      "3               0.385567    0.911994                       0.0              0   \n",
      "4               0.112681    1.376155                       0.0              0   \n",
      "\n",
      "   source_SEO  browser_FireFox  browser_IE  browser_Opera  browser_Safari  \\\n",
      "0           1                0           0              0               0   \n",
      "1           0                0           0              0               0   \n",
      "2           1                0           0              1               0   \n",
      "3           1                0           0              0               1   \n",
      "4           0                0           0              0               1   \n",
      "\n",
      "   sex_M  \n",
      "0      1  \n",
      "1      0  \n",
      "2      1  \n",
      "3      1  \n",
      "4      1  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "fraud_data = feature_engineering(fraud_data)\n",
    "print(fraud_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You are trying to merge on object and int64 columns. If you wish to proceed you should use pd.concat",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m merged_df \u001b[38;5;241m=\u001b[39m merge_geolocation(fraud_data, ip_to_country)\n",
      "File \u001b[0;32m~/week8/notebooks/../scripts/data_cleaning.py:159\u001b[0m, in \u001b[0;36mmerge_geolocation\u001b[0;34m(fraud_df, geo_df)\u001b[0m\n\u001b[1;32m    156\u001b[0m geo_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mupper_bound_ip_address\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m geo_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mupper_bound_ip_address\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mint64)\n\u001b[1;32m    158\u001b[0m \u001b[38;5;66;03m# Instead of looping over every row, use a vectorized approach to match IP ranges\u001b[39;00m\n\u001b[0;32m--> 159\u001b[0m merged_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(fraud_df, geo_df, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m, left_on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mip_int\u001b[39m\u001b[38;5;124m'\u001b[39m, right_on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlower_bound_ip_address\u001b[39m\u001b[38;5;124m'\u001b[39m, suffixes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_fraud\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_geo\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m    161\u001b[0m \u001b[38;5;66;03m# Log the merged data sample\u001b[39;00m\n\u001b[1;32m    162\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMerged DataFrame sample:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mmerged_df\u001b[38;5;241m.\u001b[39mhead()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/reshape/merge.py:110\u001b[0m, in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mleft : DataFrame or named Series\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    108\u001b[0m     validate: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    109\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m--> 110\u001b[0m     op \u001b[38;5;241m=\u001b[39m _MergeOperation(\n\u001b[1;32m    111\u001b[0m         left,\n\u001b[1;32m    112\u001b[0m         right,\n\u001b[1;32m    113\u001b[0m         how\u001b[38;5;241m=\u001b[39mhow,\n\u001b[1;32m    114\u001b[0m         on\u001b[38;5;241m=\u001b[39mon,\n\u001b[1;32m    115\u001b[0m         left_on\u001b[38;5;241m=\u001b[39mleft_on,\n\u001b[1;32m    116\u001b[0m         right_on\u001b[38;5;241m=\u001b[39mright_on,\n\u001b[1;32m    117\u001b[0m         left_index\u001b[38;5;241m=\u001b[39mleft_index,\n\u001b[1;32m    118\u001b[0m         right_index\u001b[38;5;241m=\u001b[39mright_index,\n\u001b[1;32m    119\u001b[0m         sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[1;32m    120\u001b[0m         suffixes\u001b[38;5;241m=\u001b[39msuffixes,\n\u001b[1;32m    121\u001b[0m         indicator\u001b[38;5;241m=\u001b[39mindicator,\n\u001b[1;32m    122\u001b[0m         validate\u001b[38;5;241m=\u001b[39mvalidate,\n\u001b[1;32m    123\u001b[0m     )\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result(copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/reshape/merge.py:707\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[1;32m    699\u001b[0m (\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_join_keys,\n\u001b[1;32m    701\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_join_keys,\n\u001b[1;32m    702\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjoin_names,\n\u001b[1;32m    703\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_merge_keys()\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# validate the merge keys dtypes. We may need to coerce\u001b[39;00m\n\u001b[1;32m    706\u001b[0m \u001b[38;5;66;03m# to avoid incompatible dtypes\u001b[39;00m\n\u001b[0;32m--> 707\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_coerce_merge_keys()\n\u001b[1;32m    709\u001b[0m \u001b[38;5;66;03m# If argument passed to validate,\u001b[39;00m\n\u001b[1;32m    710\u001b[0m \u001b[38;5;66;03m# check if columns specified as unique\u001b[39;00m\n\u001b[1;32m    711\u001b[0m \u001b[38;5;66;03m# are in fact unique.\u001b[39;00m\n\u001b[1;32m    712\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/reshape/merge.py:1340\u001b[0m, in \u001b[0;36m_MergeOperation._maybe_coerce_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1334\u001b[0m     \u001b[38;5;66;03m# unless we are merging non-string-like with string-like\u001b[39;00m\n\u001b[1;32m   1335\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[1;32m   1336\u001b[0m         inferred_left \u001b[38;5;129;01min\u001b[39;00m string_types \u001b[38;5;129;01mand\u001b[39;00m inferred_right \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m string_types\n\u001b[1;32m   1337\u001b[0m     ) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   1338\u001b[0m         inferred_right \u001b[38;5;129;01min\u001b[39;00m string_types \u001b[38;5;129;01mand\u001b[39;00m inferred_left \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m string_types\n\u001b[1;32m   1339\u001b[0m     ):\n\u001b[0;32m-> 1340\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1342\u001b[0m \u001b[38;5;66;03m# datetimelikes must match exactly\u001b[39;00m\n\u001b[1;32m   1343\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m needs_i8_conversion(lk\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m needs_i8_conversion(rk\u001b[38;5;241m.\u001b[39mdtype):\n",
      "\u001b[0;31mValueError\u001b[0m: You are trying to merge on object and int64 columns. If you wish to proceed you should use pd.concat"
     ]
    }
   ],
   "source": [
    "merged_df = merge_geolocation(fraud_data, ip_to_country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "univariate_analysis(fraud_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bivariate_analysis(fraud_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the cleaned data to a new CSV file\n",
    "logging.info(\"Saving the cleaned data to 'Cleaned_Fraud_Data.csv'...\")\n",
    "fraud_data.to_csv('../data/Cleaned_Fraud_Data.csv', index=False)\n",
    "\n",
    "logging.info(\"Data cleaning and preprocessing completed successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
